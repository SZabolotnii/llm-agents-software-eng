# Частина 7: Безпека моделей коду

Моделі коду (Code LLMs) здійснюють революцію в розробці ПЗ, але разом із зростанням їхніх можливостей зростає і занепокоєння щодо безпеки генерованого коду. Цей розділ представляє повний огляд викликів безпеки та стратегій їх пом'якшення, організований навколо чотирьох критичних аспектів: (1) Безпека на етапі попереднього навчання; (2) Безпека на етапі післянавчання; (3) Red-teaming оцінка; та (4) Безпека агентів кодування.

---

### Таксономія ключових аспектів безпеки Code LLM

Для систематизації безпеки моделей коду ми виділяємо наступну структуру:

*   **Безпека на етапі попереднього навчання (Safety Pre-training)**
    *   Походження даних, безпека та ліцензійна відповідність (Data Provenance, Security, License Compliance).
    *   Аудит та очищення тренувальних даних (Training-data Auditing and Cleaning).
    *   Прогалини в регулюванні та стандартах (The Regulatory and Standards Gap).
    *   Стійкість до змагальних трансформацій коду (Robustness Against Adversarial Code Transformation).
    *   Оцінка та пом'якшення ризиків конфіденційності (Privacy Risk Assessment and Mitigation).
    *   Оцінка та пом'якшення упередженості (Bias Assessment and Mitigation).
*   **Безпека на етапі післянавчання (Safety Post-training)**
    *   Побудова безпечних наборів даних (Training Data Construction).
    *   Безпечне контрольоване донавчання (Safety Supervised Fine-tuning).
    *   Розширена оптимізація переваг (Advanced Preference Optimization).
    *   Узгодження безпеки коду (Code Safety Alignment).
*   **Red-Teaming (Змагальне тестування)**
    *   Маніпуляції на рівні промптів (Prompt-Level Manipulation).
    *   Семантичні та контекстуальні маніпуляції (Semantic and Contextual Manipulation).
    *   Маніпуляції робочим процесом агентів (Agentic Workflow Manipulation).
*   **Безпека агентів кодування (Coding Agentic Safety)**
    *   Основи безпечних середовищ виконання (Foundations in Secure Execution Environments).
    *   Проактивний захист та валідація перед виконанням (Proactive Defense and Pre-Execution Validation).
    *   Нагляд під час виконання (Runtime Oversight) та контроль намірів (Intent Grounding).

---

## 7.1 Безпека на етапі попереднього навчання

Попередня підготовка закладає фундамент безпеки. Проблема полягає в тому, що моделі коду навчаються на публічних репозиторіях, де вразливі шаблони накопичувалися десятиліттями. Емпіричні дослідження на бенчмарках (**CodeQL**, **CodeSecEval**, **HumanEval**) показують, що навіть передові моделі, такі як **Qwen3** та **DeepSeek-R1**, часто генерують небезпечні рішення, слідуючи шляху «найменшого опору» з тренувальних даних.

### 7.1.1 Походження даних та ліцензійна відповідність
При роботі з трильйонами токенів критично важливим є встановлення надійної системи управління даними. Такі проекти, як **BigCode (The Stack)**, відфільтрували 102 ТБ сирих даних до 6.4 ТБ коду з дозволеними ліцензіями. Проте автоматизоване виявлення ліцензій (license detection) залишається недосконалим, а дедуплікація коду — відкритою проблемою для юридичної чистоти.

### 7.1.2 Аудит та очищення даних
Це «перша лінія оборони»:
*   **Евристичні фільтри:** Використання регулярних виразів та правил для виявлення відомих експлойтів та небезпечних API.
*   **Класифікатори:** Використання потужних моделей для виявлення зловживань у великих масштабах.
*   **Синтетичні приклади відмови (Refusal Exemplars):** Навчання моделі розпізнавати та відхиляти небезпечні запити ще на етапі пре-тренінгу.

### 7.1.3 Прогалини в регулюванні та стандартах
В індустрії ШІ спостерігається «вакуум стандартів» порівняно з традиційною розробкою ПЗ (де існують SBOM та CRA). На 2025 рік відсутня єдина міжнародна нормативна база, яка б регулювала безпеку згенерованого коду. Регуляції на кшталт EU AI Act дають лише загальні принципи, не надаючи інструментів для перевірки коду на рівні CWE (Common Weakness Enumeration).

### 7.1.4 Стійкість до змагальних трансформацій
Код дозволяє трансформації, що зберігають семантику, але змінюють синтаксис (обфускація, кодування Base64, зміна потоку управління). Прості фільтри промптів легко обходяться такими методами. Головним викликом тут є **дилема вірності-різноманітності (fidelity-diversity dilemma)**: як створити достатньо різноманітні змагальні приклади, не порушивши при цьому функціональну коректність коду. Рішенням є **змагальне тренування (adversarial training)**, де модель вчиться глибинним абстрактним уявленням коду.

### 7.1.5 Конфіденційність та PII
Публічний код часто містить персональні дані (PII) та секрети (API-ключі). 
*   **Пайплайн очищення:** включає створення набору «еталонних» PII, тренування детектора та маскування даних у всьому корпусі.
*   **Дедуплікація:** Виявлено, що дублювання даних є головним каталізатором витоку приватної інформації, оскільки моделі схильні запам'ятовувати саме повторювані фрагменти.
*   **Ризики під час виводу (Inference):** Чутлива інформація може витікати через атаки сторонніми каналами на **KV-cache** або через архітектури **RAG**, де ризик зміщується з параметрів моделі на зовнішню базу знань.

### 7.1.6 Оцінка та пом'якшення упередженості (Bias)
Упередженість у Code LLM проявляється у назвах змінних, коментарях та навіть алгоритмічній логіці, що підкріплює соціальні стереотипи.
*   **Метрики:** Використовуються CBS (Core Bias Score), CBS_U@K (стабільність безпечних відповідей) та CBS_I@K (стійкість упереджень).
*   **Критичне спостереження:** Безпека у чаті (на природній мові) не гарантує безпеку у коді. Моделі, що відмовляються відповідати на образливі запити в чаті, можуть все одно генерувати упереджений код.

---

## 7.2 Узгодження після навчання (Safety Post-training)

### 7.2.1 Необхідність узгодження
Оскільки пре-тренінг базується на імітації, виникає розрив між «знаннями» моделі про безпеку та її реальною поведінкою. Дослідження показують, що навіть просунуті моделі можуть видавати до 40% вразливого коду. Пост-тренінг (SFT та RLHF) стає обов'язковим для впровадження принципів безпеки.

### Таблиця 7.1: Матриця функцій безпеки для методів післянавчання

| Метод | Людська розмітка (H) | ШІ-суддя | Вериф. інстр. | Ток-рівень | AST/Struct-aware | Рантайм-захист | Ризик надмір. відмови | CI/CD |
| :--- | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: |
| **SFT: vuln-fix** | \cmark | \xmark | \xmark | \xmark | \xmark | \xmark | \xmark | \xmark |
| **SFT: safety inst.** | \cmark | \xmark | \xmark | \xmark | \xmark | \xmark | \xmark | \xmark |
| **SFT: tools-in-loop** | \xmark | \xmark | \cmark | \xmark | \cmark | \xmark | \xmark | \cmark |
| **PEFT (Safe LoRA)** | \xmark | \xmark | \xmark | \xmark | \xmark | \xmark | \xmark | \xmark |
| **DPO/IPO/KTO** | \cmark | \xmark | \xmark | \xmark | \xmark | \xmark | \xmark | \xmark |
| **Localized Pref. (LPO)** | \xmark | \cmark | \cmark | \cmark | \xmark | \xmark | \xmark | \xmark |
| **Structure-aware pref.** | \xmark | \xmark | \cmark | \xmark | \cmark | \xmark | \xmark | \xmark |
| **RLHF (human)** | \cmark | \xmark | \xmark | \xmark | \xmark | \xmark | \cmark | \xmark |
| **RLAIF (AI judge)** | \xmark | \cmark | \xmark | \xmark | \xmark | \xmark | \cmark | \xmark |
| **Safe-RLHF** | \xmark | \cmark | \cmark | \xmark | \cmark | \xmark | \cmark | \xmark |
| **S-GRPO** | \xmark | \xmark | \cmark | \xmark | \cmark | \xmark | \xmark | \cmark |
| **Safety Editor Policy** | \xmark | \xmark | \cmark | \xmark | \cmark | \cmark | \xmark | \cmark |
| **SEAL / ProSec** | \xmark | \cmark | \cmark | \xmark | \cmark | \xmark | \xmark | \xmark |
| **SAST feedback loop** | \xmark | \xmark | \cmark | \xmark | \cmark | \xmark | \xmark | \cmark |

*Рисунок 7.1: Пайплайн генерації даних для безпекового узгодження*
![Пайплайн генерації даних для безпекового узгодження](./figures/code_posttraining.png)

Пайплайн включає:
1.  **Реальні дані:** Видобуток пар «вразливість-патч» з CVEfixes та BigVul.
2.  **Синтетичні дані:** Використання вчителя-LLM (HexaCoder, ProSec) для створення прикладів для конкретних CWE.
3.  **Дистиляція переваг:** Створення трійок `<prompt, secure_code, insecure_code>` для DPO.

### 7.2.2 Контрольоване донавчання (SFT)
*   **Content-based:** Навчання на парах `(vulnerable, fixed)`.
*   **Instruction-based:** Навчання на інструкціях типу «Знайди та виправ SQL-ін'єкцію».
*   **Feedback-based:** Інтеграція інструментів (SAST, тести) у цикл навчання.

### 7.2.3 Локалізована оптимізація переваг (LPO)
Оскільки вразливості часто ховаються в окремих токенах, **LPO** фокусує функцію втрат саме на них, а не на всьому рядку коду. Це дозволяє зменшити кількість вразливостей на 19-40%, водночас покращуючи загальну якість коду на 3-10%.

### 7.2.4 Навчання з підкріпленням (RL)
RL дозволяє моделі вчитися на наслідках рішень.
*   **Веріфіковані сигнали:** Успішна компіляція, проходження тестів, результати SAST.
*   **ШІ-судді:** Оцінюють тонкі логічні вразливості та «чистоту» коду.
*   **Виклики:** *Reward hacking* (коли модель видаляє тести, щоб вони «пройшли») та *Alignment tax* (зниження продуктивності через надмірну обережність).

---

## 7.3 Red-Teaming та змагальні атаки

### 7.3.1 Маніпуляція на рівні промптів
*   **Heuristic Jailbreaking:** Рольові ігри (DAN), префікс-ін'єкції («Звісно, ось вразливий SQL-запит...»).
*   **Optimization-Based (GCG):** Використання градієнтного спуку для створення універсальних суфіксів, що «зламують» чорні скриньки.
*   **Fuzzing (GPTFuzzer):** Використання атакуючої LLM для автоматичної генерації тисяч варіантів атак.
*   **Multi-turn Attacks (RedCoder):** Серія діалогів, що поступово послаблюють захист моделі через самонавіювання.

### Таблиця 7.2: Аналіз технік Red-Teaming для Code LLM
(\cmark — сприятливо для атакуючого, \xmark — несприятливо, $\sim$ — середньо)

| Метод | Ефективність | Складність | Автоматизація | Вартість | Переносність |
| :--- | :---: | :---: | :---: | :---: | :---: |
| **Heuristic Jailbreaking** | $\sim$ | \cmark | \xmark | \cmark | \xmark |
| **GCG (Оптимізація)** | \cmark | \xmark | \cmark | \xmark | \cmark |
| **Generation / Fuzzing** | \cmark | $\sim$ | \cmark | \xmark | $\sim$ |
| **Multi-Turn Attacks** | \cmark | \xmark | $\sim$ | $\sim$ | $\sim$ |
| **Trust Boundary Exploit** | \cmark | $\sim$ | \xmark | \cmark | \cmark |
| **Indirect Prompt Injection** | \cmark | $\sim$ | \xmark | \cmark | \cmark |
| **Obfuscation Attacks** | $\sim$ | \cmark | \cmark | \cmark | \cmark |
| **Tool Misuse** | \cmark | $\sim$ | \xmark | \cmark | $\sim$ |
| **Sandbox Escape** | \cmark | \xmark | \xmark | \cmark | \xmark |
| **Automated Exploitation (AVDE)**| \cmark | \xmark | \cmark | \xmark | $\sim$ |

### 7.3.2 Семантична та контекстуальна маніпуляція
*   **DeceptPrompt:** Використання розділення між «довіреною інструкцією» та «недовіреними даними». Шкідливий промпт ховається в даних.
*   **Непряма ін'єкція промптів:** Отруєння зовнішніх джерел (веб-сторінок), які агент зчитує під час роботи.
*   **Крос-лінгвальні атаки:** Використання низькоресурсних мов, для яких безпекові фільтри натреновані гірше.

### 7.3.3 Маніпуляції робочим процесом агентів (Agentic Workflow)
Це вершина небезпеки, де атакується не текст, а дії:
*   **Зловживання інструментами (Tool Misuse):** Введення шкідливих аргументів у функції (наприклад, SQL-ін'єкція через легітимний інструмент доступу до БД).
*   **Sandbox Escape:** Спроби агента згенерувати код, який вийде за межі контейнера Docker/VM на хост-систему.
*   **Автономна експлуатація (AVDE):** Перетворення агента на повноцінний хакерський інструмент (**RedCodeAgent**), який самостійно виконує цикл розвідки, сканування та зламу.

### Таблиця 7.3: Матриця Загроза × Оцінка × Контроль

| Сімейство атак | Unsafe Code | Exfiltration | Tool Misuse | Env. Comp. | GuidedBench | Verifiers | Pre-Exec | Runtime | Isolation |
| :--- | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: |
| **Prompt-level** | \cmark | - | - | - | \cmark | \cmark | \cmark | \cmark | - |
| **Trust-boundary** | \cmark | \cmark | - | - | \cmark | \cmark | \cmark | \cmark | - |
| **Indirect Injection** | - | \cmark | \cmark | - | \cmark | - | \cmark | \cmark | - |
| **Tool Misuse** | - | \cmark | \cmark | - | \cmark | \cmark | \cmark | \cmark | - |
| **Sandbox Escape** | - | - | - | \cmark | - | \cmark | - | - | \cmark |

---

## 7.4 Стратегії пом'якшення ризиків (Mitigation)

### 7.4.1 Безпечні середовища виконання (Containerization)
1.  **Docker:** Ефективний, але вразливий до втечі через спільне ядро (наприклад, через вразливості **path misresolution**, що дозволяють вийти за межі файлової системи контейнера).
2.  **nsjail:** Дозволяє фільтрацію системних викликів (seccomp) на рівні процесів.
3.  **MicroVM (Firecracker):** Найвищий рівень ізоляції на рівні заліза, що захищає від атак типу Spectre/MDS.

### 7.4.2 Проактивна валідація (Pre-Execution)
*   **Modernized Code Analysis:** Використання SAST та DAST у циклі «інструмент-в-петлі» (**AutoSafeCoder**, **AgentArmor**).
*   **Мультиагентне рецензування:** Схема «Coder-Critic», де одна модель пише код, а інша його перевіряє.
*   **Формальні методи:** Математичні докази коректності коду (**SafePlan**) та перевірка намірів (Intent Verification) перед виконанням.

### 7.4.3 Рантайм-нагляд (Runtime Oversight)
*   **Guardian Agents:** Окрема модель (**AgentSentinel**, **GuardAgent**), яка моніторить дії основного агента в реальному часі.
*   **Verifiable Policies:** Використання формальних специфікацій (**AgentSpec**) для обмеження прав доступу, які неможливо обійти через промпт.
*   **Ctrl-Z:** Механізм «скасування» або перегенерації дій агента, якщо виявлено «дрейф намірів» (intent drift). Майбутні системи використовуватимуть каузальні діаграми (causal influence diagrams) для кращого розуміння причинно-наслідкових зв'язків у діях агентів.

---

**Наступний розділ:** [Частина 8: Рецепти навчання Code LLM](./Part_08_Training_Recipes.md)
