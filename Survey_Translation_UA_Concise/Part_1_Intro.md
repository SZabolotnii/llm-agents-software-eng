# Частина 1: Вступ

## 1. Вступ

Поява великих мовних моделей (LLM) спричинила парадигмальний зсув в автоматизованій розробці програмного забезпечення, фундаментально переосмисливши відносини між людським наміром та виконуваним кодом. Сучасні LLM досягли вражаючих можливостей у широкому спектрі завдань, пов'язаних з кодом, включаючи доповнення коду, переклад, виправлення та генерацію. Ці LLM ефективно дистилюють роки накопиченої експертизи програмування в доступні інструменти, що слідують інструкціям і можуть бути використані розробниками будь-якого рівня кваліфікації, використовуючи код з таких джерел, як GitHub, Stack Overflow та інші веб-сайти, пов'язані з кодом.

Серед завдань, пов'язаних з LLM, **генерація коду** є однією з найбільш трансформаційних, дозволяючи безпосередньо перекладати описи природною мовою у функціональний вихідний код, тим самим усуваючи традиційні бар'єри між доменними знаннями та технічною реалізацією. Ця можливість вийшла за межі академічної цікавості і стала комерційною реальністю через низку комерційних та відкритих інструментів, включаючи:

1. **GitHub Copilot** (Microsoft) — надає інтелектуальне доповнення коду в середовищах розробки
2. **Cursor** (Anysphere) — AI-first редактор коду, що дозволяє конверсаційне програмування
3. **CodeGeeX** (Zhipu AI) — пропонує багатомовну генерацію коду
4. **CodeWhisperer** (Amazon) — безшовно інтегрується з сервісами AWS
5. **Claude Code** (Anthropic) / **Gemini CLI** (Google) — інструменти командного рядка, що дозволяють розробникам делегувати завдання кодування безпосередньо Claude або Gemini з терміналу для агентних робочих процесів кодування

Ці застосунки переформатовують робочі процеси розробки програмного забезпечення, кидають виклик традиційним припущенням про продуктивність програмування та переосмислюють межу між людською креативністю та машинною допомогою.

![Огляд еволюції Code LLM](./figures/coder_overview.png)
*Рисунок 1: Огляд еволюції великих мовних моделей коду (Code-LLM) та пов'язаних екосистем з 2021 по 2025 рік. Ландшафт починається з ранніх моделей і швидко розширюється в різноманітний набір LLM-кодерів протягом 2022–2024 років. З 2025 року фокус досліджень зміщується до навчання на основі підкріплення (RL), агентів програмної інженерії (SWE) та нових архітектур, таких як дифузійні моделі коду. Паралельно виникає багата екосистема термінальних інструментів, інтеграцій IDE та плагінів, що підкреслює перехід від чистого моделювання до практичних застосунків, орієнтованих на розробників.*

---

## 1.1 Еволюційна траєкторія генерації коду

Еволюційна траєкторія генерації коду розкриває переконливу історію технологічного дозрівання та парадигмальних зсувів. Ранні підходи, обмежені евристичними правилами та ймовірнісними граматичними фреймворками, були за своєю природою крихкими — оптимізованими для вузьких доменів і стійкими до узагальнення в широкому різноманітті програмних контекстів.

Поява архітектур на основі трансформерів (таких як CodeBERT, GraphCodeBERT) представляла не просто поступове покращення, а фундаментальне переосмислення проблемного простору, використовуючи механізми уваги та масштаб для захоплення складних відносин між наміром природної мови та структурою коду.

Більш того, ці моделі демонструють **емерджентні здатності слідування інструкціям**, які не були явно запрограмовані чи безпосередньо оптимізовані, що свідчить про те, що здатність перекладати високорівневі цілі в виконувані реалізації може бути природним наслідком вивчення багатих представлень у масштабі.

Ця **демократизація кодування**, що дозволяє неекспертам генерувати складні програми через природну мову, несе глибокі наслідки для розвитку робочої сили, темпів інновацій та самої суті обчислювальної грамотності в 21 столітті.

---

## 1.2 Генералісти проти спеціалістів

Сучасний ландшафт Code LLM розкриває стратегічну біфуркацію між генералістськими та спеціалістськими підходами, кожен з яких має різні переваги та компроміси:

### Генералістські моделі
- **GPT** (GPT-4, GPT-5), **Claude** (Claude 3.7, Claude 4, Claude 4.5), **LLaMA** (LLaMA 2, LLaMA 3, LLaMA 4)
- Пропонують вражаючу широту, використовуючи величезні корпуси природної мови поряд з кодом
- Розвивають нюансоване розуміння контексту, наміру та доменних знань

### Спеціалізовані Code LLM
- **StarCoder**, **Code LLaMA**, **DeepSeek-Coder**, **CodeGemma**, **QwenCoder**
- Досягають кращої продуктивності на специфічних для коду бенчмарках
- Фокусоване попереднє навчання на даних, орієнтованих на програмування
- Архітектурні оптимізації для конкретних завдань

Драматичні покращення продуктивності — від одиничних цифр до 95%+ показників успіху на стандартизованих бенчмарках, таких як **HumanEval**, відображають як алгоритмічні інновації, так і глибші інсайти. Хоча код є високо формалізованим, він має спільні основні характеристики з природною мовою, особливо в композиційній семантиці та контекстних залежностях.

---

## 1.3 Прогалини в існуючих дослідженнях

Незважаючи на енергійну дослідницьку діяльність та швидке комерційне впровадження, критична прогалина зберігається між широтою інновацій та глибиною систематичного аналізу в літературі. Існуючі огляди значною мірою приймали панорамні підходи, досліджуючи широкі категорії завдань, пов'язаних з кодом, або фокусуючись на ранніх поколіннях моделей, залишаючи сучасні досягнення неадекватно синтезованими.

**Критично недостатньо досліджені:**
- Складні стратегії курації даних сучасних систем
- Баланс між кількістю та якістю в інструкційному налаштуванні
- Методи узгодження для вирівнювання поведінки моделі з наміром розробника
- Включення людського зворотного зв'язку для уточнення виходів
- Передові парадигми промптингу (chain-of-thought reasoning, few-shot learning)
- Поява автономних агентів кодування, здатних до багатокрокової декомпозиції проблем
- Підходи RAG (Retrieval-Augmented Generation), що ґрунтують виходи на авторитетних посиланнях
- Нові фреймворки оцінювання, що виходять за межі простої бінарної коректності

Останні LLM, такі як **Kimi-K2**, **GLM-4.5/4.6**, **Qwen3Coder**, **Kimi-Dev**, **Claude 4.5**, **Deepseek-V3.2-Exp** та **GPT-5**, втілюють ці інновації, проте їхні внески залишаються розкиданими по різних публікаціях без цілісної інтеграції.

---

## 1.4 Порівняння з існуючими оглядами

**Таблиця 1: Порівняння між нашим дослідженням та існуючими роботами**

| Огляд | Сфера | Фокус на коді | LLM | Pretrain | SFT | RL | Застосування | Рецепти навчання |
|--------|-------|---------------|-----|----------|-----|----|--------------|--------------------|
| A Survey on Language Models for Code | Всі | ✓ | ✓ | ✓ | ✓ | ✗ | ✓ | ✗ |
| Deep Learning for Code Generation: A Survey | DL, Code Gen, Automated SE | ✓ | ✗ | ✗ | ✗ | ✗ | ✓ | ✓ |
| Code to Think, Think to Code | Code reasoning, planning, debugging | ✓ | ✗ | ✗ | ✗ | ✗ | ✓ | ✗ |
| A Survey on LLMs for Code Generation | Code Generation, Data Process | ✓ | ✓ | ✓ | ✗ | ✗ | ✓ | ✗ |
| A Survey of ML for Big Code and Naturalness | Code patterns, model design | ✗ | ✗ | ✗ | ✗ | ✗ | ✓ | ✗ |
| A Survey on Code Generation with LLM-based Agents | Code Gen, LLM Agents, Multi-agent | ✓ | ✓ | ✓ | ✓ | ✓ | ✓ | ✗ |
| A Survey of Automatic Source Code Summarization | Code Summarization, Program Analysis | ✓ | ✗ | ✗ | ✗ | ✗ | ✓ | ✓ |
| A Review of Automatic Source Code Summarization | Code Summarization, Program Analysis | ✓ | ✗ | ✗ | ✗ | ✗ | ✓ | ✗ |
| Survey on NN-based Automatic Source Code Summarization | Intelligent SE, Code Summarization | ✓ | ✗ | ✗ | ✗ | ✗ | ✓ | ✗ |
| A Survey of Large Language Models | General LLM | ✗ | ✓ | ✓ | ✓ | ✗ | ✓ | ✗ |
| Source code data augmentation for deep learning | Code Data Augmentation | ✓ | ✓ | ✗ | ✓ | ✗ | ✓ | ✗ |
| A Survey of Vibe Coding with LLMs | Vibe Coding | ✗ | ✓ | ✓ | ✓ | ✗ | ✓ | ✗ |
| **Наш огляд** | **Всі** | **✓** | **✓** | **✓** | **✓** | **✓** | **✓** | **✓** |

---

## 1.5 Внески цього огляду

Щоб надати всебічне та практичне дослідження від фундаментальних моделей коду до агентів та застосунків, ми представляємо детальний посібник, що поєднує теоретичні основи з реалізаціями в сучасних системах генерації коду.

**Наша робота робить кілька ключових внесків:**

1. **Уніфікована таксономія сучасних Code LLM** — простежуємо їхню еволюцію від ранніх моделей на основі трансформерів до останнього покоління систем з інструкційним налаштуванням та емерджентними здатностями міркування

2. **Систематичний аналіз повного технічного конвеєра:**
   - Стратегії курації та попередньої обробки даних
   - Цілі попереднього навчання та архітектурні інновації
   - Передові методології тонкого налаштування (supervised instruction tuning та reinforcement learning)

3. **Дослідження передових парадигм:**
   - Техніки промптингу (chain-of-thought)
   - Підходи retrieval-augmented generation
   - Автономні агенти кодування, здатні до складного багатокрокового вирішення проблем

4. **Критична оцінка ландшафту бенчмарків:**
   - Сильні та слабкі сторони методологій оцінювання
   - Виклики оцінювання не лише функціональної коректності, але й якості коду, підтримуваності та ефективності

5. **Синтез інсайтів з проривних моделей:**
   - GPT-5, Claude 4.5 та інші
   - Виявлення трендів та відкритих викликів, що формуватимуть наступне покоління систем генерації коду

6. **Обширні експерименти:**
   - Всебічне дослідження попереднього навчання коду, supervised fine-tuning та reinforcement learning
   - Багатовимірний аналіз: закони масштабування, фреймворки, гіперпараметри, архітектури та набори даних

**Цей огляд має на меті служити як:**
- Всебічний довідник для дослідників, що входять у галузь
- Стратегічна дорожня карта для практиків, що прагнуть використовувати ці технології в продакшн-середовищах
